* [BERT Chatbot](https://blog.est.ai/2019/11/task-oriented-dialog-systems-meet-bert/)

##  BERT ?

**BERT**는  
**B**idirectional  
**E**ncoder  
**R**epresentations from  
**T**ransformers  

> **사람처럼 문장을 이해하는 인공지능 언어 모델**

---

BERT는 **문장을 읽고, 의미를 파악할 수 있는 AI**입니다.

기존 AI는 문장을 왼쪽→오른쪽으로만 읽었는데,  
**BERT는 앞뒤를 동시에 보면서 해석**

그래서 **문맥을 잘 이해**해요.


##  특별한 이유

- 기존보다 훨씬 더 **정확하고 똑똑하게 문장을 이해**함
- 여러 언어 처리 문제를 **하나의 모델**로 해결할 수 있음
- 다양한 분야에서 바로 써먹을 수 있음 (이걸 **사전학습 모델**이라고 함함)


BERT는 문장과 관련된 글을 보고,  
해답을 찾아서 정확히 답해줄 수 있다.

<br>
<br>
<br>

# 본문 요약 


## 일반 챗봇 작동 매커니즘

> 나 집 근처 피자집 예약해줘
- 💡 **무슨 일을 하라는 건지** (의도) → "피자집 예약"
- 📍 **어떤 정보가 필요한지** (슬롯) → "위치 = 집 근처"

## 🤔 기존 챗봇의 문제점

1. **미리 알려준 말만 이해할 수 있었음**  
   → "예술의 전당" 같은 장소 이름을 **미리 학습하지 않으면 못 알아들음**  
2. **새로운 요청에 약했음**  
   → 새로운 의도(예: "전시회 예매")가 생기면 **다시 학습시켜야 함**


##  그래서 등장한 것이 BERT

**BERT**는 구글이 만든 똑똑 언어 모델

- **앞뒤 문맥을 모두 보고 문장을 이해함**  
  (예: “나는 **은행**에 갔다” → 돈 관련인지, 강가인지 알아냄)
- 사람처럼 문장을 파악하는 데 강함 


## BERT를 챗봇에 쓰면 좋은 점 

1. **처음 듣는 장소나 말도 이해할 수 있음**  
   → “예술의 전당” 같은 장소 이름이 **처음 보는 말이어도** 문맥을 보고 "여긴 목적지구나!" 하고 이해함

2. **새로운 기능 추가가 쉬워짐**  
   → 예전에는 “택시 부르기” 챗봇 따로, “배달 주문” 챗봇 따로 만들었어야 했는데  
   → BERT는 **기본적인 언어 이해 능력**이 좋아서 하나로도 가능

3. **잘 모르는 말도 유사한 말로 대체해 이해함**  
   → "출발지"랑 "origin"이 같다는 걸 알아냄

---

##  정리하면?
* BERT라는 언어 모델을 사용  

→ 우리가 처음 말하는 내용을 쉽게 이해  
→ 새로운 기능을 쉽게 추가